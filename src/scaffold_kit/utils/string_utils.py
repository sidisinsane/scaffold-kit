"""A set of utilities for string manipulation.

This module provides functions for transliterating unicode characters and
creating URL-friendly "slugs" from text.

Demo:
    To run the module's demonstration code, use the following command:

    $ uv run python -m scaffold_kit.utils.string_utils
"""

from __future__ import annotations

import re
import unicodedata


DIACRITICS_MAP: dict[str, str] = {
    "Ã€": "A",
    "Ã": "A",
    "Ãƒ": "A",
    "Ã„": "Ae",
    "Ã…": "A",
    "Ä€": "A",
    "Ä‚": "A",
    "Ä„": "A",
    "Ã ": "a",
    "Ã¡": "a",
    "Ã£": "a",
    "Ã¤": "ae",
    "Ã¥": "a",
    "Ä": "a",
    "Äƒ": "a",
    "Ä…": "a",
    "Ã‡": "C",
    "Ä†": "C",
    "Äˆ": "C",
    "ÄŒ": "C",
    "Ã§": "c",
    "Ä‡": "c",
    "Ä‰": "c",
    "Ä": "c",
    "Ä": "D",
    "Ä": "D",
    "Ä": "d",
    "Ä‘": "d",
    "Ãˆ": "E",
    "Ã‰": "E",
    "áº¼": "E",
    "Ã‹": "E",
    "Ä”": "E",
    "Ä’": "E",
    "Äš": "E",
    "Ä˜": "E",
    "Ã¨": "e",
    "Ã©": "e",
    "áº½": "e",
    "Ã«": "e",
    "Ä•": "e",
    "Ä—": "e",
    "Ä›": "e",
    "Ä™": "e",
    "Ä ": "G",
    "Ä¢": "G",
    "Äœ": "G",
    "Ä": "G",
    "Ä¡": "g",
    "Ä£": "g",
    "Ä": "g",
    "ÄŸ": "g",
    "Ä¤": "H",
    "Ä¦": "H",
    "Ä¥": "h",
    "Ä§": "h",
    "ÃŒ": "I",
    "Ã": "I",
    "Ã": "I",
    "Ã": "I",
    "Ä®": "I",
    "Äª": "I",
    "Ä°": "I",
    "Ã¬": "i",
    "Ã­": "i",
    "Ã®": "i",
    "Ã¯": "i",
    "Ä«": "i",
    "Ä©": "i",
    "Ä´": "J",
    "Äµ": "j",
    "Ä¶": "K",
    "Ä·": "k",
    "Ä¹": "L",
    "Ä»": "L",
    "Ä½": "L",
    "Ä¿": "L",
    "Äº": "l",
    "Ä¼": "l",
    "Ä¾": "l",
    "Ã‘": "N",
    "Å…": "N",
    "Å‡": "N",
    "Å†": "n",
    "Åˆ": "n",
    "Ã’": "O",
    "Ã“": "O",
    "Ã”": "O",
    "Ã•": "O",
    "Ã–": "Oe",
    "ÅŒ": "O",
    "Å": "O",
    "Å": "O",
    "Ã²": "o",
    "Ã³": "o",
    "Ã´": "o",
    "Ãµ": "o",
    "Ã¶": "oe",
    "Å": "o",
    "Å": "o",
    "Å‘": "o",
    "Ã™": "U",
    "Ãš": "U",
    "Ã›": "U",
    "Ãœ": "Ue",
    "Åª": "U",
    "Å®": "U",
    "Å°": "U",
    "Å²": "U",
    "Ã¹": "u",
    "Ãº": "u",
    "Ã»": "u",
    "Ã¼": "ue",
    "Å«": "u",
    "Å¯": "u",
    "Å±": "u",
    "Å´": "W",
    "Åµ": "w",
    "Ã": "Y",
    "Å¸": "Y",
    "Ã½": "y",
    "Ã¿": "y",
    "Å¶": "Y",
    "Å·": "y",
    "Å½": "Z",
    "Å»": "Z",
    "Åº": "z",
    "Å¼": "z",
    "Å¾": "z",
}
"""Constant signifying diacritics map."""  # pylint: disable=W0105


LIGATURES_MAP: dict[str, str] = {
    "Ã¦": "ae",
    "Ã†": "Ae",
    "Å“": "oe",
    "Å’": "Oe",
    "ÃŸ": "ss",
    "ï¬€": "ff",
    "ï¬": "fi",
    "ï¬‚": "fl",
    "ï¬ƒ": "ffi",
    "ï¬„": "ffl",
    "ï¬…": "ft",
    "ï¬†": "st",
    "Ä³": "ij",
    "Ä²": "Ij",
    "Ê’": "ezh",
    "Æ·": "Ez",
}
"""Constant signifying ligatures map."""  # pylint: disable=W0105

TRANSLITERATE_MAP = {**DIACRITICS_MAP, **LIGATURES_MAP}
"""Constant signifying transliterate map (diacritics and ligatures merged)."""  # pylint: disable=W0105


def transliterate(text: str) -> str:
    """Transliterates unicode characters to their closest ascii replacements.

    This function replaces diacritics, ligatures, and stylistic variants with
    base ASCII letters, e.g., 'Ã±' â†’ 'n', 'Ã¦' â†’ 'ae', 'ÃŸ' â†’ 'ss'. All remaining
    non-ASCII characters are removed by a second decomposing and encoding
    pass.

    Args:
        text: Any string containing unicode characters.

    Returns:
        A plain ASCII string where every non-ASCII glyph has been converted or
        dropped, resulting in lossy but url-safe output.

    Raises:
        None â€“ all standard exceptions are caught internally.

    Examples:
        Handling diacritics:

        >>> transliterate("FranÃ§ois CafÃ©")
        'Francois Cafe'

        Mixed scripts and special characters:

        >>> transliterate("StraÃŸe â€“ cafÃ© naÃ¯f")
        'Strasse  cafe naif '

        Ligatures and stylists variants:

        >>> transliterate("EncyclopÃ¦dia & ï¬‚uffy Å“uf")
        'Encyclopaedia & fluffy oeu'

        Emojis and math get stripped:

        >>> transliterate("Î± â‰¤ Â½ ğŸ˜Š")
        '  '  # empty string, every char is non-ASCII
    """
    # 1. Map predefined characters to their ASCII replacements.
    text = text.translate(str.maketrans(TRANSLITERATE_MAP))
    # 2. Normalize and remove all remaining non-ASCII characters.
    text = (
        unicodedata.normalize("NFKD", text)
        .encode("ascii", "ignore")
        .decode("utf-8")
    )

    return text


def slugify(text: str) -> str:
    """Converts a given string into an url-safe, ascii-only slug.

    This function removes or transliterates diacritics, ligatures, and other
    non-ascii characters while normalising whitespace and punctuation into
    hyphens. The result contains only lowercase letters ([a-z]), digits
    ([0-9]) and hyphens, making it suitable for use in urls, file names or keys.

    Args:
        text: The original, possibly unicode string that needs to be slugified.

    Returns:
        A hyphen-separated ascii slug derived from `text`. If `text` is empty or
        the transformation leads to an empty string the returned slug will also
        be empty ("").

    Raises:
        None â€“ all standard exceptions are caught internally.

    Examples:
        Basic usage:

        >>> slugify("CafÃ© crÃ¨me Ã  la franÃ§aise")
        'cafe-creme-a-la-francaise'

        Complex input with punctuation and mixed spaces:

        >>> slugify("  Â¡Hola! Â¿QuÃ© tal?  ")
        'hola-que-tal'

        Already ascii and clean strings remain the same, except for case:

        >>> slugify("Valid-slug-already-given")
        'valid-slug-already-given'

        Empty or symbol-only input results in an empty string:

        >>> slugify("!!!!!  ???")
        ''
    """
    # 1. Replace diacritics and ligatures.
    text = transliterate(text)
    # 2. Convert to lowercase and remove leading/trailing spaces.
    text = text.lower().strip()
    # 3. Remove non-alphanumeric characters except spaces and hyphens.
    text = re.sub(r"[^\w\s-]", "", text)
    # 4. Replace consecutive spaces or hyphens with a single hyphen.
    text = re.sub(r"[\s_-]+", "-", text)
    # 5. Remove leading/trailing hyphens.
    text = re.sub(r"^-+|-+$", "", text)

    return text


if __name__ == "__main__":
    text_list = [
        "HÃ«llÃ´,    wÃ¶rld!",
        "Ã§a va Ãªtre une journÃ©e spÃ©ciale.",
        "Ich liebe Deutsche KÃ¼che!",
        "Â¿CÃ³mo estÃ¡s? Â¡Hasta maÃ±ana!",
        "Å½ivot je lijep, ali Äesto i kratak.",
        "NÃ£o sei o que fazer agora...",
        "J'aime les fromages franÃ§ais!",
        "KÃ¼ÃŸ mich, meine SchÃ¶ne!",
        "Å koda, Å¾e jsem to nevÃ­m.",
        "Â¿DÃ³nde estÃ¡ el baÃ±o, por favor?",
        "EncyclopÃ¦dia & ï¬‚uffy Å“uf",
        "StraÃŸe â€“ cafÃ© naÃ¯f",
    ]

    transliterate_list = [[text, transliterate(text)] for text in text_list]
    slugify_list = [[text, slugify(text)] for text in text_list]

    print("\n=== transliterate ===\n")
    for key, value in transliterate_list:
        print(f"{key}: {value}")

    print("\n=== slugify ===\n")
    for key, value in slugify_list:
        print(f"{key}: {value}")
